{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Low-Resource\" Text Classification: A Parameter-Free Classification Method with Compressors\n",
    "\n",
    "Jiang et. al, Association for Computational Linguistics: ACL 2023, pages 6810-6828"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalized Compression Distance (NCD) utilizing compressed length $C(x)$ to approximate Kolmogorov complexity $K(x)$\n",
    "\n",
    "$NCD(x, y) = \\cfrac{C(xy) - \\min{\\left( C(x), C(y) \\right)}}{\\max{\\left( C(x), C(y) \\right)}}$\n",
    "\n",
    "Where in this case, $C(x)$ means the length of $x$ after being compressed by gzip. $C(xy)$ is the compressed length of concatenation of $x$ and $y$. With the distance matrix NCD provides, we can then use $k$-nearest-neighbor to perform classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datasets\n",
    "import gzip\n",
    "\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gzip_compress(x):\n",
    "    return len(gzip.compress(x.encode()))\n",
    "\n",
    "def ncd(Cx1, Cx2, Cx1x2):\n",
    "    return (Cx1x2 - min(Cx1, Cx2)) / max(Cx1, Cx2)\n",
    "\n",
    "def ncd_gzip(training_set, test_set, content, k):\n",
    "    res = []\n",
    "\n",
    "    for x1 in test_set:\n",
    "        \n",
    "        Cx1 = compress(x1[content])\n",
    "\n",
    "        distance_from_x1 = []\n",
    "\n",
    "        for x2 in training_set:\n",
    "\n",
    "            Cx2 = compress(x2[content])\n",
    "\n",
    "            x1x2 = \" \".join([x1[content], x2[content]])\n",
    "            Cx1x2 = compress(x1x2)\n",
    "\n",
    "            distance = ncd(Cx1, Cx2, Cx1x2)\n",
    "            distance_from_x1.append(distance)\n",
    "\n",
    "        sorted_idx = np.argsort(np.array(distance_from_x1))\n",
    "        top_k_class = training_set[sorted_idx[:k]]['label']\n",
    "\n",
    "        predict_class = max(set(top_k_class), key=top_k_class.count)\n",
    "\n",
    "        res.append([predict_class, x1['label']])\n",
    "    \n",
    "    return pd.DataFrame(res, columns=['predict', 'true'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing on the 20News dataset\n",
    "\n",
    "Dataset with highest number of words by document (avg. of 406 words), written in English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/home/fausto/.cache/huggingface/datasets/SetFit___json/SetFit--20_newsgroups-f05bfc706e284479/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5c2b08b3fee485e98b3aec8e7764e19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"SetFit/20_newsgroups\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (5657, 3)\n",
      "Test set size: (38, 3)\n"
     ]
    }
   ],
   "source": [
    "training_set = dataset['train'].shard(num_shards=2, index=0)\n",
    "test_set = dataset['test'].shard(num_shards=200, index=0)\n",
    "\n",
    "print('Training set size:', training_set.shape)\n",
    "print('Test set size:', test_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = ncd_gzip(training_set, test_set, content='text', k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.25      0.36         8\n",
      "           1       0.00      0.00      0.00         3\n",
      "           2       0.33      0.25      0.29         4\n",
      "           3       0.50      0.14      0.22         7\n",
      "           4       0.00      0.00      0.00         3\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       1.00      0.67      0.80         3\n",
      "           7       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "           9       0.33      1.00      0.50         1\n",
      "          11       0.00      0.00      0.00         0\n",
      "          12       0.00      0.00      0.00         1\n",
      "          13       0.00      0.00      0.00         0\n",
      "          14       0.20      1.00      0.33         1\n",
      "          15       0.00      0.00      0.00         0\n",
      "          16       1.00      1.00      1.00         2\n",
      "          18       0.00      0.00      0.00         0\n",
      "          19       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.26        38\n",
      "   macro avg       0.22      0.24      0.19        38\n",
      "weighted avg       0.41      0.26      0.29        38\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fausto/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/fausto/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/fausto/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/fausto/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/fausto/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/fausto/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(res['predict'], res['true']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 1, 1, 0, 0, 0, 1],\n",
       "       [0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 2, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]])"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(res['predict'], res['true'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing on the SogouNews dataset\n",
    "\n",
    "Dataset with highest number of words by document (avg. of 589 words), written in foreign language Sogou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset sogou_news (/home/fausto/.cache/huggingface/datasets/sogou_news/default/0.0.0/dd1f148239e73c4200e6965abe37873b6bff9f511d3a7b290338d3750e780cf1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f685940f37894a27b6ca0db618a94391",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"sogou_news\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (900, 3)\n",
      "Test set size: (60, 3)\n"
     ]
    }
   ],
   "source": [
    "training_set = dataset['train'].shard(num_shards=500, index=0)\n",
    "test_set = dataset['test'].shard(num_shards=1000, index=0)\n",
    "\n",
    "print('Training set size:', training_set.shape)\n",
    "print('Test set size:', test_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = ncd_gzip(training_set, test_set, content='content', k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.71      0.77        17\n",
      "           1       1.00      0.71      0.83         7\n",
      "           2       0.53      0.80      0.64        10\n",
      "           3       0.94      0.89      0.91        18\n",
      "           4       0.89      1.00      0.94         8\n",
      "\n",
      "    accuracy                           0.82        60\n",
      "   macro avg       0.84      0.82      0.82        60\n",
      "weighted avg       0.85      0.82      0.82        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_res = pd.DataFrame(res, columns=['predict', 'true'])\n",
    "\n",
    "print(metrics.classification_report(df_res['predict'], df_res['true']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12,  0,  4,  0,  1],\n",
       "       [ 0,  5,  2,  0,  0],\n",
       "       [ 1,  0,  8,  1,  0],\n",
       "       [ 1,  0,  1, 16,  0],\n",
       "       [ 0,  0,  0,  0,  8]])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(df_res['predict'], df_res['true'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
